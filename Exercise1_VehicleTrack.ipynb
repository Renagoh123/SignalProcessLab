{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Vehicle Track"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DIa5cDXjQvH"
      },
      "source": [
        "## Task1: Car Detection on Main Street"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC7-dIz-mbOM"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6CNCZyjhA2r",
        "outputId": "7d942b36-a9e5-4cfe-ed30-234c7a606cd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless \n",
        "!pip install pyttsx3\n",
        "!pip install numpy\n",
        "!pip install opencv-python\n",
        "!pip install pypiwin32\n",
        "\n",
        "import cv2\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8N3u7VmFmlai"
      },
      "source": [
        "Create functions to import the provided videos and output path settings for saving the processed video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMAqYyWmho-6",
        "outputId": "8183cb65-f6c2-4725-c7c8-482226af1ba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video loaded: /content/Traffic_Laramie_1.mp4\n",
            "FPS: 25, Width: 1040, Height: 600, Total Frames: 4448\n",
            "Output video writer initialized at `/content/Traffic_Detection_Output.mp4`\n"
          ]
        }
      ],
      "source": [
        "def initialize_video(video_path):\n",
        "    \"\"\"Initialize video capture and retrieve video properties.\"\"\"\n",
        "    video = cv2.VideoCapture(video_path)\n",
        "    if not video.isOpened():\n",
        "        raise ValueError(f\"Error: Cannot open video at {video_path}\")\n",
        "\n",
        "    fps = int(video.get(cv2.CAP_PROP_FPS))\n",
        "    frame_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    frame_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    print(f\"Video loaded: {video_path}\")\n",
        "    print(f\"FPS: {fps}, Width: {frame_width}, Height: {frame_height}, Total Frames: {total_frames}\")\n",
        "\n",
        "    return video, fps, frame_width, frame_height, total_frames\n",
        "\n",
        "def initialize_video_writer(output_path, fps, frame_width, frame_height):\n",
        "    \"\"\"Initialize video writer for output video.\"\"\"\n",
        "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "    output_video = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "    if not output_video.isOpened():\n",
        "        raise ValueError(f\"Error: Cannot create output video at `{output_path}`\")\n",
        "\n",
        "    print(f\"Output video writer initialized at `{output_path}`\")\n",
        "    return output_video\n",
        "\n",
        "# Initialize video and output writer\n",
        "video1_path = \"/content/Traffic_Laramie_1.mp4\"\n",
        "output1_path = \"/content/Traffic_Detection_Output.mp4\"\n",
        "video, fps, frame_width, frame_height, total_frames = initialize_video(video1_path)\n",
        "output_video = initialize_video_writer(output1_path, fps, frame_width, frame_height)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGgAt_h82SZQ"
      },
      "source": [
        "Create functions for **Frame Preprocessing** and **Background Subtraction** (MOG2) for car detection and tracking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZ1iS3pkZ816"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess each frame\n",
        "def preprocess_frame(frame):\n",
        "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "    return blurred\n",
        "\n",
        "\n",
        "# Function to apply frame differencing\n",
        "def apply_frame_differencing(current_frame, initial_frame):\n",
        "    frame_diff = cv2.absdiff(initial_frame, current_frame)\n",
        "    _, thresh = cv2.threshold(frame_diff, 25, 255, cv2.THRESH_BINARY)\n",
        "    return thresh\n",
        "\n",
        "\n",
        "# Initialize MOG2 background subtractor\n",
        "bg_subtractor = cv2.createBackgroundSubtractorMOG2(history=500, varThreshold=16, detectShadows=True)\n",
        "# Function to apply MOG background subtractor\n",
        "def apply_background_subtraction(frame):\n",
        "    fg_mask = bg_subtractor.apply(frame)\n",
        "    # Morphological operations\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    cleaned_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
        "    dilated_mask = cv2.dilate(cleaned_mask, kernel, iterations=2)\n",
        "    return dilated_mask\n",
        "\n",
        "\n",
        "# Function to detect and draw green bounding boxes around detected cars on the main street\n",
        "def detect_cars(frame, mask):\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    # Gets the height of the video frame\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Dynamic threshold based on frame size\n",
        "    MIN_CONTOUR_AREA = (frame_width * frame_height) * 0.001\n",
        "\n",
        "    # Loop through each detected contour\n",
        "    for contour in contours:\n",
        "       # Focus on big objects like cars\n",
        "        if cv2.contourArea(contour) < MIN_CONTOUR_AREA:\n",
        "            continue\n",
        "\n",
        "        # Get the bounding box coordinates\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "        # Focus only on the bottom half (main street area)\n",
        "        if y > height / 2:\n",
        "          # Green box for main street cars\n",
        "          cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzXbnSxi0b6o"
      },
      "source": [
        "Preprocessing the video to detect cars on main street"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5RWgu-CKZ851",
        "outputId": "09108360-fae6-446a-b716-c68f51ab421b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial frame read successfully.\n",
            "Starting video processing...\n",
            "The car detection is done!\n"
          ]
        }
      ],
      "source": [
        "# Read the initial frame for frame differencing\n",
        "ret, initial_frame = video.read()\n",
        "if not ret:\n",
        "    print(\"Error: Could not read the initial frame.\")\n",
        "    video.release()\n",
        "    exit(1)\n",
        "\n",
        "# Preprocess the initial frame (grayscale + blur)\n",
        "initial_gray = cv2.cvtColor(initial_frame, cv2.COLOR_BGR2GRAY)\n",
        "initial_blur = cv2.GaussianBlur(initial_gray, (5, 5), 0)\n",
        "print(\"Initial frame read successfully.\")\n",
        "\n",
        "\n",
        "print(\"Starting video processing...\")\n",
        "while True:\n",
        "    ret, frame = video.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Preprocess the current frame\n",
        "    preprocessed_frame = preprocess_frame(frame)\n",
        "\n",
        "    # Frame differencing\n",
        "    frame_diff = apply_frame_differencing(preprocessed_frame, initial_blur)\n",
        "\n",
        "    # Background subtraction (MOG2)\n",
        "    foreground_mask = apply_background_subtraction(preprocessed_frame)\n",
        "\n",
        "    # Combine frame differencing and MOG2 masks\n",
        "    combined_mask = cv2.bitwise_or(frame_diff, foreground_mask)\n",
        "\n",
        "    # Detect the cars on mainstreet and draw bounding boxes around detected cars\n",
        "    processed_frame = detect_cars(frame, combined_mask)\n",
        "\n",
        "    # Write processed frame to output video\n",
        "    output_video.write(processed_frame)\n",
        "\n",
        "    # Press 'q' to exit early\n",
        "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "print(\"The car detection is done!\")\n",
        "\n",
        "# Release resources\n",
        "video.release()\n",
        "output_video.release()\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPh2W5IkQHf7"
      },
      "source": [
        "## Task2: Car Counting Towards City Center"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRJVhs02QIt3"
      },
      "outputs": [],
      "source": [
        "# Function to draw the detection zone to define the counting area\n",
        "def draw_detection_zone(frame, rect_center, rect_size, angle):\n",
        "    \"\"\"Draw the rotated detection zone on the video frame.\"\"\"\n",
        "    # Create the rotated rectangle\n",
        "    rotated_rect = (rect_center, rect_size, angle)\n",
        "    box = cv2.boxPoints(rotated_rect).astype(int)\n",
        "\n",
        "    # Draw the rotated detection zone\n",
        "    cv2.polylines(frame, [box], isClosed=True, color=(255, 255, 0), thickness=2)\n",
        "    cv2.putText(frame, \"Detection Zone\", (rect_center[0] - 40, rect_center[1] - 60),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)\n",
        "\n",
        "    return box\n",
        "\n",
        "\n",
        "# Function to detect and count cars based on motion within the detection zone\n",
        "def detect_and_count_cars(frame, mask, detection_zone_box):\n",
        "    \"\"\"Detect and count cars using contours and centroid tracking.\"\"\"\n",
        "    global tracked_cars, car_count\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    detected_centroids = []\n",
        "\n",
        "    # Gets the height of the video frame\n",
        "    height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    # Loop through each detected contour\n",
        "    for contour in contours:\n",
        "        # Focus on big objects like cars\n",
        "        if cv2.contourArea(contour) < 2500:\n",
        "            continue\n",
        "\n",
        "        # Get the bounding box adn centroid coordinates\n",
        "        x, y, w, h = cv2.boundingRect(contour)\n",
        "        cX, cY = x + w // 2, y + h // 2\n",
        "\n",
        "        # Focus only on the bottom half (main street area)\n",
        "        # Draw bounding box and centroid\n",
        "        if y > height / 2:\n",
        "          cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "          cv2.circle(frame, (cX, cY), 5, (0, 0, 255), -1)\n",
        "\n",
        "        # Check if the centroid is inside the detection zone\n",
        "        if cv2.pointPolygonTest(detection_zone_box, (cX, cY), False) >= 0:\n",
        "            detected_centroids.append((cX, cY))\n",
        "\n",
        "    # Update tracked cars and avoid duplicate counting\n",
        "    new_tracked_cars = []\n",
        "    for cX, cY in detected_centroids:\n",
        "        found = False\n",
        "        for car_x, car_y, frames_left in tracked_cars:\n",
        "            if abs(cX - car_x) < 20 and abs(cY - car_y) < 20:\n",
        "                new_tracked_cars.append((cX, cY, FRAME_TIMEOUT))\n",
        "                found = True\n",
        "                break\n",
        "\n",
        "        if not found:\n",
        "            car_count += 1\n",
        "            print(f\"Car counted! Total count: {car_count}\")\n",
        "            new_tracked_cars.append((cX, cY, FRAME_TIMEOUT))\n",
        "\n",
        "    # Remove expired tracked cars\n",
        "    tracked_cars = [(x, y, frames_left - 1) for x, y, frames_left in tracked_cars if frames_left > 0]\n",
        "    tracked_cars.extend(new_tracked_cars)\n",
        "\n",
        "    # Display car count\n",
        "    cv2.putText(frame, f\"Cars to City: {car_count}\", (10, 40),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "    return frame\n",
        "\n",
        "\n",
        "def process_video(video, output_video, fps, total_frames):\n",
        "    \"\"\"Process video frames, detect cars, and calculate cars per minute.\"\"\"\n",
        "    # Read the initial frame for frame differencing\n",
        "    ret, initial_frame = video.read()\n",
        "    if not ret:\n",
        "        print(\"Error: Could not read the initial frame.\")\n",
        "        video.release()\n",
        "        exit(1)\n",
        "\n",
        "    # Preprocess the initial frame (grayscale + blur)\n",
        "    initial_gray = cv2.cvtColor(initial_frame, cv2.COLOR_BGR2GRAY)\n",
        "    initial_blur = cv2.GaussianBlur(initial_gray, (5, 5), 0)\n",
        "    print(\"Initial frame read successfully.\")\n",
        "\n",
        "    global car_count, tracked_cars, FRAME_TIMEOUT\n",
        "    # Car tracking variables\n",
        "    car_count = 0\n",
        "    tracked_cars = []\n",
        "    FRAME_TIMEOUT = 30\n",
        "\n",
        "    # Detection zone parameters\n",
        "    rect_center = (60, int(frame_height / 2 + 50))\n",
        "    rect_size = (70, 85)\n",
        "    angle = 10\n",
        "\n",
        "\n",
        "    print(\"Starting video processing...\")\n",
        "    while True:\n",
        "        ret, frame = video.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Preprocess current frame\n",
        "        preprocessed_frame = preprocess_frame(frame)\n",
        "\n",
        "        # Apply frame differencing and background subtraction\n",
        "        frame_diff = apply_frame_differencing(preprocessed_frame, initial_blur)\n",
        "        foreground_mask = apply_background_subtraction(preprocessed_frame)\n",
        "        combined_mask = cv2.bitwise_or(frame_diff, foreground_mask)\n",
        "\n",
        "        # Draw detection zone and get its coordinates\n",
        "        detection_zone_box = draw_detection_zone(frame, rect_center, rect_size, angle)\n",
        "\n",
        "        # Detect and count cars\n",
        "        processed_frame = detect_and_count_cars(frame, combined_mask, detection_zone_box)\n",
        "\n",
        "        # Write processed frame to output video\n",
        "        output_video.write(processed_frame)\n",
        "\n",
        "        # Exit early if 'q' is pressed\n",
        "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
        "            break\n",
        "\n",
        "    print(\"Video processing complete....\")\n",
        "\n",
        "    # Calculate cars per minute\n",
        "    video_duration_minutes = (total_frames / fps) / 60\n",
        "    cars_per_minute = car_count / video_duration_minutes if video_duration_minutes > 0 else 0.0\n",
        "\n",
        "    # Final output\n",
        "    print(f\"\\n----- Final Results -----\")\n",
        "    print(f\"Total cars counted passing to the city center: {car_count}\")\n",
        "    print(f\"Cars per minute: {cars_per_minute:.2f}\")\n",
        "    print(\"Video processing complete.\")\n",
        "\n",
        "    # Release resources\n",
        "    video.release()\n",
        "    output_video.release()\n",
        "    cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVn5GInTQIpP",
        "outputId": "579bd5a0-26f5-4a5e-aaa1-bf0243b7281e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video loaded: /content/Traffic_Laramie_1.mp4\n",
            "FPS: 25, Width: 1040, Height: 600, Total Frames: 4448\n",
            "Output video writer initialized at `/content/Traffic_1_Counting_Output.mp4`\n",
            "Initial frame read successfully.\n",
            "Starting video processing...\n",
            "Car counted! Total count: 1\n",
            "Car counted! Total count: 2\n",
            "Car counted! Total count: 3\n",
            "Car counted! Total count: 4\n",
            "Car counted! Total count: 5\n",
            "Car counted! Total count: 6\n",
            "Video processing complete....\n",
            "\n",
            "----- Final Results -----\n",
            "Total cars counted passing to the city center: 6\n",
            "Cars per minute: 2.02\n",
            "Video processing complete.\n"
          ]
        }
      ],
      "source": [
        "# Initialize video and output writer for Video 1\n",
        "video_1_path = \"/content/Traffic_Laramie_1.mp4\"\n",
        "output_1_path = \"/content/Traffic_1_Counting_Output.mp4\"\n",
        "video_1, fps_1, frame_width_1, frame_height_1, total_frames_1 = initialize_video(video_1_path)\n",
        "output_video_1 = initialize_video_writer(output_1_path, fps_1, frame_width_1, frame_height_1)\n",
        "\n",
        "# Process video 1\n",
        "process_video(video_1, output_video_1, fps_1, total_frames_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T5hos7NQQIsf",
        "outputId": "6ab29c02-d985-49ab-9d10-da602bc6e0d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video loaded: /content/Traffic_Laramie_2.mp4\n",
            "FPS: 25, Width: 1040, Height: 600, Total Frames: 2642\n",
            "Output video writer initialized at `/content/Traffic_2_Counting_Output.mp4`\n",
            "Initial frame read successfully.\n",
            "Starting video processing...\n",
            "Car counted! Total count: 1\n",
            "Car counted! Total count: 2\n",
            "Car counted! Total count: 3\n",
            "Car counted! Total count: 4\n",
            "Video processing complete....\n",
            "\n",
            "----- Final Results -----\n",
            "Total cars counted passing to the city center: 4\n",
            "Cars per minute: 2.27\n",
            "Video processing complete.\n"
          ]
        }
      ],
      "source": [
        "# Initialize video and output writer for Video 2\n",
        "video_2_path = \"/content/Traffic_Laramie_2.mp4\"\n",
        "output_2_path = \"/content/Traffic_2_Counting_Output.mp4\"\n",
        "video_2, fps_2, frame_width_2, frame_height_2, total_frames_2 = initialize_video(video_2_path)\n",
        "output_video_2 = initialize_video_writer(output_2_path, fps_2, frame_width_2, frame_height_2)\n",
        "\n",
        "# Process video 2\n",
        "process_video(video_2, output_video_2, fps_2, total_frames_2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ReNNC4PQIxu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
